{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Initialize a SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"LocalRowCountFoo\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# # Step 2: Create an RDD with the \"Hello World\" message\n",
    "# data = [\"Hello\", \"World\"]\n",
    "# rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "# # Step 3: Perform an action to collect and print the data\n",
    "# result = rdd.collect()\n",
    "# print(\" \".join(result))\n",
    "\n",
    "# # Step 4: Stop the Spark session\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=====================================================>   (51 + 3) / 54]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+---+--------------------+--------------------+\n",
      "| ID|FirstName| LastName|Age|               Email|             Country|\n",
      "+---+---------+---------+---+--------------------+--------------------+\n",
      "|  1|Elizabeth|  Bennett| 32|elizabeth.bennett...|               Kenya|\n",
      "|  2| Benjamin|   Garcia| 28|benjamin.garcia@s...|         Switzerland|\n",
      "|  3|Elizabeth|   Jordan| 56|elizabeth.jordan@...|              Poland|\n",
      "|  4|Charlotte|    Scott| 59|charlotte.scott@d...|              Greece|\n",
      "|  5|  William|   Carter| 47|william.carter@de...|              Russia|\n",
      "|  6|     Noah|    Adams| 40|noah.adams@sample...|           Australia|\n",
      "|  7|     Lucy| Phillips| 42|lucy.phillips@dem...|             Belgium|\n",
      "|  8|   Thomas|   Miller| 34|thomas.miller@sam...|           Indonesia|\n",
      "|  9|   Thomas|   Murphy| 36|thomas.murphy@exa...|               China|\n",
      "| 10|    Layla|  Collins| 19|layla.collins@sam...|           Argentina|\n",
      "| 11|   Thomas|     Hall| 28|thomas.hall@examp...|               Kenya|\n",
      "| 12|    Caleb|    Adams| 48|caleb.adams@demo.net|             Ireland|\n",
      "| 13|   Easton|     Reed| 33|easton.reed@demo.net|            Colombia|\n",
      "| 14|    Henry|    Scott| 22|henry.scott@demo.net|           Argentina|\n",
      "| 15|      Ava|   Martin| 31|ava.martin@exampl...|         South Korea|\n",
      "| 16|Elizabeth|    Perez| 52|elizabeth.perez@e...|             Belgium|\n",
      "| 17|   Adrian|Hernandez| 21|adrian.hernandez@...|              Israel|\n",
      "| 18|Christian|   Nguyen| 38|christian.nguyen@...|           Australia|\n",
      "| 19| Jonathan| Peterson| 26|jonathan.peterson...|              Turkey|\n",
      "| 20|Elizabeth|   Cooper| 51|elizabeth.cooper@...|United Arab Emirates|\n",
      "+---+---------+---------+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('dummy_data.csv',header=True,inferSchema=True)\n",
    "df.createOrReplaceTempView('customer')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====================================================>   (51 + 3) / 54]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|      country|customer_count|\n",
      "+-------------+--------------+\n",
      "|       Russia|       2000579|\n",
      "|       Sweden|       2001276|\n",
      "|  Philippines|       1999695|\n",
      "|    Singapore|       1998271|\n",
      "|     Malaysia|       2000236|\n",
      "|       Turkey|       1997944|\n",
      "|      Germany|       2001110|\n",
      "|       France|       2000593|\n",
      "|       Greece|       1999727|\n",
      "|    Argentina|       3998312|\n",
      "|      Belgium|       2001571|\n",
      "|      Finland|       1997907|\n",
      "|         Peru|       2001010|\n",
      "|        China|       2000004|\n",
      "|        India|       2001237|\n",
      "|United States|       1999854|\n",
      "|        Chile|       2000366|\n",
      "|      Nigeria|       1997912|\n",
      "|        Italy|       1998986|\n",
      "|       Norway|       1996855|\n",
      "+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_counts ='''\n",
    "select \n",
    "    country, \n",
    "    count(*) as customer_count\n",
    "from customer \n",
    "group by country\n",
    "'''\n",
    "sql_df = spark.sql(sql_counts)\n",
    "sql_df.show()\n",
    "sql_df.createOrReplaceTempView('customer_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>    (50 + 4) / 54]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+---------------+\n",
      "|         avg_count|      stddev_count|total_customers|\n",
      "+------------------+------------------+---------------+\n",
      "|2040816.3265306123|285470.89293199603|      100000000|\n",
      "+------------------+------------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_stats ='''\n",
    "\n",
    "    SELECT \n",
    "        AVG(customer_count) AS avg_count, \n",
    "        STDDEV(customer_count) AS stddev_count,\n",
    "        sum(customer_count) as total_customers\n",
    "    FROM customer_counts\n",
    "\n",
    "'''\n",
    "avg_df = spark.sql(sql_stats)\n",
    "avg_df.show()\n",
    "avg_df.createOrReplaceTempView('customer_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:======================================================> (53 + 1) / 54]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+--------------------+----------+\n",
      "|      country|customer_count|             z_score|is_suspect|\n",
      "+-------------+--------------+--------------------+----------+\n",
      "|       Russia|       2000579| -0.1409507152107361|         0|\n",
      "|       Sweden|       2001276|-0.13850913529048117|         0|\n",
      "|  Philippines|       1999695|-0.14404735315837647|         0|\n",
      "|    Singapore|       1998271|-0.14903560252199624|         0|\n",
      "|     Malaysia|       2000236| -0.1421522387582934|         0|\n",
      "|       Turkey|       1997944|-0.15018107832389488|         0|\n",
      "|      Germany|       2001110|-0.13909063065168967|         0|\n",
      "|       France|       2000593|-0.14090167343328477|         0|\n",
      "|       Greece|       1999727|-0.14393525766705917|         0|\n",
      "|    Argentina|       3998312|   6.857076227157408|         1|\n",
      "|      Belgium|       2001571|-0.13747575497989983|         0|\n",
      "|      Finland|       1997907| -0.1503106887357305|         0|\n",
      "|         Peru|       2001010|-0.13944092906205624|         0|\n",
      "|        China|       2000004| -0.1429649310703438|         0|\n",
      "|        India|       2001237|-0.13864575167052415|         0|\n",
      "|United States|       1999854|-0.14349037868589362|         0|\n",
      "|        Chile|       2000366|-0.14169685082481687|         0|\n",
      "|      Nigeria|       1997912|-0.15029317381521218|         0|\n",
      "|        Italy|       1998986|-0.14653096888787537|         0|\n",
      "|       Norway|       1996855| -0.1539958280127867|         0|\n",
      "+-------------+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "sql_z ='''\n",
    "SELECT \n",
    "    c.country,\n",
    "    c.customer_count,\n",
    "    (c.customer_count - s.avg_count) / s.stddev_count AS z_score,\n",
    "    case when abs((c.customer_count - s.avg_count) / s.stddev_count) > 3 then 1 else 0 end   AS is_suspect\n",
    "FROM customer_counts c\n",
    "CROSS JOIN customer_stats s;\n",
    "'''\n",
    "z_df = spark.sql(sql_z)\n",
    "z_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
