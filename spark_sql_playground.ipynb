{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Initialize a SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "    .appName(\"LocalRowCountFoo\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# # Step 2: Create an RDD with the \"Hello World\" message\n",
    "# data = [\"Hello\", \"World\"]\n",
    "# rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "# # Step 3: Perform an action to collect and print the data\n",
    "# result = rdd.collect()\n",
    "# print(\" \".join(result))\n",
    "\n",
    "# # Step 4: Stop the Spark session\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('dummy_data.csv',header=True,inferSchema=True)\n",
    "df.createOrReplaceTempView('customer')\n",
    "\n",
    "df.printSchema()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_counts ='''\n",
    "select \n",
    "    country, \n",
    "    count(*) as customer_count\n",
    "from customer \n",
    "group by country\n",
    "order by country\n",
    "'''\n",
    "sql_df = spark.sql(sql_counts)\n",
    "sql_df.show()\n",
    "sql_df.createOrReplaceTempView('customer_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_stats ='''\n",
    "\n",
    "    SELECT \n",
    "        AVG(customer_count) AS avg_count, \n",
    "        STDDEV(customer_count) AS stddev_count,\n",
    "        sum(customer_count) as total_customers\n",
    "    FROM customer_counts\n",
    "\n",
    "'''\n",
    "avg_df = spark.sql(sql_stats)\n",
    "avg_df.show()\n",
    "avg_df.createOrReplaceTempView('customer_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_z ='''\n",
    "SELECT \n",
    "    c.country,\n",
    "    c.customer_count,\n",
    "    (c.customer_count - s.avg_count) / s.stddev_count AS z_score,\n",
    "    case when abs((c.customer_count - s.avg_count) / s.stddev_count) > 3 then 1 else 0 end   AS is_suspect\n",
    "FROM customer_counts c\n",
    "CROSS JOIN customer_stats s\n",
    "order by c.country\n",
    "'''\n",
    "z_df = spark.sql(sql_z)\n",
    "z_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dauphine = spark.sql(\"select * from customer where firstname = 'John' and lastname='Dauphine'\")\n",
    "\n",
    "df_dauphine.show()\n",
    "display(df_dauphine.count())\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
